import torch
from torch.utils.data import DataLoader, TensorDataset
import random
from ReverbNet import ReverberationNet

# è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯é‡å¤æ€§
torch.manual_seed(42)
random.seed(42)

# --- è¶…å‚æ•° ---
batch_size = 32
input_dim = 64  # è¾“å…¥ç‰¹å¾ç»´åº¦ d
seq_len = 10    # åºåˆ—é•¿åº¦ L
num_epochs = 50  # å‡å°‘epochæ•°é‡ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
device = 'cuda' if torch.cuda.is_available() else 'cpu'

print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# --- æ•°æ®ç”Ÿæˆ ---
# éšæœºç”Ÿæˆè¾“å…¥ (B, L, d) å’Œç›®æ ‡ (B,)
num_samples = 1000
X = torch.randn(num_samples, seq_len, input_dim)
y = torch.rand(num_samples)  # å‡è®¾æ˜¯å›å½’ä»»åŠ¡ï¼Œè¾“å‡ºæ ‡é‡

# åˆ›å»º DataLoader
dataset = TensorDataset(X, y)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# --- åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨ ---
print("åˆå§‹åŒ–ReverberationNetç½‘çŠ¶æ¨¡å‹...")
print("  â€¢ 19ä¸ªè§’è‰²æ¨¡å— - ç‰¹åŒ–ç‰¹å¾æå–")
print("  â€¢ 7ä¸ªæ•°æ®å¤„ç†å™¨ - æ•°æ®èšåˆè·¯ç”±ä¼ è¾“")
print("  â€¢ 1ä¸ªArgalliaæŒ‡æŒ¥å±‚ - å…¨å±€æ±‡èš")
model = ReverberationNet(d=input_dim).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
total_params = sum(p.numel() for p in model.parameters())
structure_info = model.get_network_structure()
print(f"æ¨¡å‹æ€»å‚æ•°æ•°é‡: {total_params:,}")
print(f"è§’è‰²æ¨¡å—æ•°é‡: {len(structure_info['roles'])}")
print(f"æ•°æ®å¤„ç†å™¨æ•°é‡: {len(structure_info['processors'])}")
print(f"æ€»è¿æ¥æ•°: {structure_info['total_connections']}")

# --- è®­ç»ƒæ¨¡å‹ ---
print("\nå¼€å§‹ç½‘çŠ¶è®­ç»ƒ...")
print("è®­ç»ƒæµç¨‹: è§’è‰²â†’é—¨æ§é€‰æ‹©â†’æ•°æ®å¤„ç†å™¨â†’åé¦ˆâ†’Argalliaâ†’è¾“å‡º")
model.train()
for epoch in range(num_epochs):
    total_loss = 0
    total_mse_loss = 0
    total_kl_loss = 0
    
    for batch_idx, (inputs, targets) in enumerate(dataloader):
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs, kl_loss, gate_probs = model(inputs)

        # å›å½’ä»»åŠ¡ä½¿ç”¨ MSE Loss
        mse_loss = torch.nn.MSELoss()(outputs.squeeze(), targets.float())
        loss = mse_loss + kl_loss * 1e-4  # è°ƒæ•´KLæƒé‡ï¼Œé€‚é…æ•°æ®å¤„ç†å™¨

        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        total_mse_loss += mse_loss.item()
        total_kl_loss += kl_loss.item()

    # è®¡ç®—å¹³å‡æŸå¤±
    avg_loss = total_loss / len(dataloader)
    avg_mse = total_mse_loss / len(dataloader)
    avg_kl = total_kl_loss / len(dataloader)
    
    # æ¯ä¸ªepochéƒ½æ‰“å°è¯¦ç»†ä¿¡æ¯
    print(f"Epoch {epoch+1:3d}/{num_epochs} | "
          f"Total Loss: {avg_loss:.6f} | "
          f"MSE Loss: {avg_mse:.6f} | "
          f"KL Loss: {avg_kl:.2f} | "
          f"Gate Probs: {len(gate_probs):2d}")

# --- æµ‹è¯•æ¨¡å‹ ---
print("\nå¼€å§‹ç½‘çŠ¶è¯„ä¼°...")
model.eval()
total_mse = 0
with torch.no_grad():
    for inputs, targets in dataloader:
        inputs, targets = inputs.to(device), targets.to(device)
        outputs, _, gate_probs = model(inputs)
        total_mse += torch.nn.MSELoss()(outputs.squeeze(), targets.float()).item()

avg_mse = total_mse / len(dataloader)
print(f"æœ€ç»ˆè¯„ä¼° MSE Loss: {avg_mse:.6f}")

# --- æ˜¾ç¤ºé—¨æ§æ¦‚ç‡ä¿¡æ¯ ---
print("\nè§’è‰²â†’æ•°æ®å¤„ç†å™¨é—¨æ§æ¦‚ç‡åˆ†æ:")
with torch.no_grad():
    sample_input = X[:1].to(device)  # å–ä¸€ä¸ªæ ·æœ¬
    _, _, gate_probs = model(sample_input)
    
    module_names = [
        "Eileen", "Pluto", "Organ", "Harp", "WolfHour", "Viola", 
        "Philip", "Cello", "CircusMaster", "Bremen", "Zaixian", 
        "Elena", "Greta", "Clarinet", "Horn", "Tuba", "Trombone", 
        "Violin1", "Violin2"
    ]
    
    print("å„è§’è‰²æ¨¡å—é—¨æ§æ¦‚ç‡ (è¿æ¥åˆ°æ•°æ®å¤„ç†å™¨çš„å¼ºåº¦):")
    for i, (name, prob) in enumerate(zip(module_names, gate_probs)):
        print(f"{i+1:2d}. {name:12s}: {prob.item():.4f}")

# --- æ˜¾ç¤ºæ•°æ®å¤„ç†å™¨è¿æ¥ä¿¡æ¯ ---
print("\næ•°æ®å¤„ç†å™¨è¿æ¥æ˜ å°„:")
role_to_processor = structure_info['role_to_processor']
processor_to_roles = structure_info['processor_to_roles']

processor_names = {
    'data_aggregator': 'æ•°æ®èšåˆå™¨',
    'stream_processor': 'æµå¤„ç†å™¨', 
    'message_router': 'æ¶ˆæ¯è·¯ç”±å™¨',
    'bandwidth_manager': 'å¸¦å®½ç®¡ç†å™¨',
    'protocol_converter': 'åè®®è½¬æ¢å™¨',
    'cache_manager': 'ç¼“å­˜ç®¡ç†å™¨',
    'sync_coordinator': 'åŒæ­¥åè°ƒå™¨'
}

for processor_key, cn_name in processor_names.items():
    connected_roles = processor_to_roles.get(processor_key, [])
    print(f"ğŸ“§ {processor_key:18s} ({cn_name})")
    print(f"   â† è¿æ¥è§’è‰²: {', '.join(connected_roles)}")

print("\nğŸ¯ ç½‘çŠ¶è¿æ¥ç‰¹ç‚¹:")
print("   â€¢ æ¯ä¸ªè§’è‰²é€šè¿‡é—¨æ§æœºåˆ¶é€‰æ‹©æ•°æ®å¤„ç†å™¨")
print("   â€¢ æ•°æ®å¤„ç†å™¨ä¸“æ³¨äºæ•°æ®èšåˆã€è·¯ç”±ã€ä¼ è¾“")
print("   â€¢ å½¢æˆè§’è‰²â†”æ•°æ®å¤„ç†å™¨çš„ç½‘çŠ¶ä¿¡æ¯æµ")
print("   â€¢ æ‰€æœ‰ä¿¡æ¯æœ€ç»ˆæ±‡èšåˆ°ArgalliaæŒ‡æŒ¥å±‚")

print("\nâœ… è®­ç»ƒå®Œæˆï¼æ•°æ®å¤„ç†å™¨æˆåŠŸä¼˜åŒ–ä¿¡æ¯ä¼ è¾“ã€‚")